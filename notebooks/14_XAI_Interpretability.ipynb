{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# ğŸ” XAI: Model Interpretability with Integrated Gradients\n",
                "\n",
                "## ëª©í‘œ / Goal\n",
                "AI Crash Generator (DriftNet)ê°€ **ì™œ** íŠ¹ì • ê²½ë¡œë¥¼ í­ë½ ê²½ë¡œë¡œ íŒë‹¨í–ˆëŠ”ì§€ ì„¤ëª…í•©ë‹ˆë‹¤.\n",
                "\n",
                "Explain **why** the AI Crash Generator (DriftNet) classified a specific path as a crash scenario.\n",
                "\n",
                "## ê¸°ë²• / Technique\n",
                "**Integrated Gradients (IG)** - Googleì—ì„œ ê°œë°œí•œ XAI ê¸°ë²•\n",
                "- ì…ë ¥ ë³€ìˆ˜(S, v, t)ì˜ ê¸°ì—¬ë„(Attribution)ë¥¼ ì •í™•íˆ ê³„ì‚°\n",
                "- ê¸°ì¤€ì (Baseline)ì—ì„œ ì…ë ¥ì ê¹Œì§€ì˜ ê·¸ë˜ë””ì–¸íŠ¸ë¥¼ ì ë¶„"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# =============================================================================\n",
                "# í™˜ê²½ ì„¤ì • / Environment Setup\n",
                "# =============================================================================\n",
                "import os\n",
                "os.environ['KMP_DUPLICATE_LIB_OK'] = 'TRUE'\n",
                "\n",
                "import sys\n",
                "sys.path.append('..')\n",
                "\n",
                "import torch\n",
                "import torch.nn.functional as F\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "from src.physics_engine import MarketSimulator\n",
                "from src.neural_engine import DriftNet\n",
                "\n",
                "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
                "print(f\"Using device: {device}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# =============================================================================\n",
                "# DriftNet íŒ¨ì¹˜ (v3 Aggressive Mode)\n",
                "# Patch DriftNet for aggressive crash generation (Control Bound: 5.0)\n",
                "# =============================================================================\n",
                "def aggressive_forward(self, S, v, t, avg_S=None):\n",
                "    \"\"\"\n",
                "    ìˆ˜ì •ëœ Forward í•¨ìˆ˜ / Modified forward function.\n",
                "    Control Boundë¥¼ 5.0ìœ¼ë¡œ í™•ëŒ€í•˜ì—¬ ë” ê°•í•œ ì œì–´ë ¥ ë¶€ì—¬.\n",
                "    Increases control bound to 5.0 for stronger crash generation.\n",
                "    \"\"\"\n",
                "    S_norm = torch.log(S + 1e-8)\n",
                "    v_norm = torch.log(v + 1e-8)\n",
                "    t_norm = t * torch.ones_like(S)\n",
                "    \n",
                "    if avg_S is None:\n",
                "        avg_S = S\n",
                "    avg_S_norm = torch.log(avg_S + 1e-8)\n",
                "    \n",
                "    x = torch.stack([S_norm, v_norm, t_norm, avg_S_norm], dim=-1)\n",
                "    raw_output = self.net(x).squeeze(-1)\n",
                "    \n",
                "    # ì œì–´ ê°•ë„ 5ë°° í™•ëŒ€ / Increase control strength 5x\n",
                "    return 5.0 * torch.tanh(raw_output)\n",
                "\n",
                "DriftNet.forward = aggressive_forward\n",
                "print(\"DriftNet patched: Control Bound = 5.0 ğŸš€\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# =============================================================================\n",
                "# ëª¨ë¸ ë° ì‹œë®¬ë ˆì´í„° ì„¤ì • / Model & Simulator Setup\n",
                "# =============================================================================\n",
                "\n",
                "# ì‹œì¥ íŒŒë¼ë¯¸í„° / Market Parameters\n",
                "S0 = 100.0\n",
                "v0 = 0.04\n",
                "r = 0.05\n",
                "T = 0.25\n",
                "dt = 0.001\n",
                "\n",
                "# Heston íŒŒë¼ë¯¸í„° / Heston Parameters\n",
                "kappa = 2.0; theta = 0.04; xi = 0.5; rho = -0.7\n",
                "\n",
                "# ì„¤ì • / Settings\n",
                "num_paths = 50000\n",
                "CRASH_THRESHOLD = 0.80  # 20% í•˜ë½ / 20% Drop\n",
                "K_crash = CRASH_THRESHOLD * S0\n",
                "\n",
                "# ì‹œë®¬ë ˆì´í„° ì´ˆê¸°í™” / Initialize Simulator\n",
                "simulator = MarketSimulator(mu=r, kappa=kappa, theta=theta, xi=xi, rho=rho, device=device)\n",
                "\n",
                "# DriftNet ì´ˆê¸°í™” / Initialize DriftNet\n",
                "drift_net = DriftNet(hidden_dim=64).to(device)\n",
                "\n",
                "print(f\"Market configured: S0={S0}, K_crash={K_crash}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# =============================================================================\n",
                "# í•™ìŠµ (ê°„ëµ ë²„ì „) / Training (Quick Version)\n",
                "# ì´ë¯¸ í•™ìŠµëœ ëª¨ë¸ì´ ìˆìœ¼ë©´ ì´ ì…€ì„ ê±´ë„ˆë›°ì…”ë„ ë©ë‹ˆë‹¤.\n",
                "# Skip this cell if you already have a trained model.\n",
                "# =============================================================================\n",
                "optimizer = torch.optim.Adam(drift_net.parameters(), lr=1e-3)\n",
                "\n",
                "def get_control_fn(model):\n",
                "    def control_fn(t, S, v, avg_S=None):\n",
                "        return model(S, v, t, avg_S)\n",
                "    return control_fn\n",
                "\n",
                "control_fn = get_control_fn(drift_net)\n",
                "\n",
                "# ë¹ ë¥¸ í•™ìŠµ (200 iterations) / Quick training (200 iterations)\n",
                "num_iters = 200\n",
                "batch_size = 10000\n",
                "\n",
                "print(\"Training DriftNet for XAI analysis...\")\n",
                "for i in range(num_iters):\n",
                "    optimizer.zero_grad()\n",
                "    \n",
                "    S, v, log_weights, _, _ = simulator.simulate_controlled(\n",
                "        S0=S0, v0=v0, T=T, dt=dt, num_paths=batch_size,\n",
                "        model_type='heston', control_fn=control_fn\n",
                "    )\n",
                "    \n",
                "    S_T = S[:, -1]\n",
                "    margin = 2.0\n",
                "    target_level = K_crash - margin\n",
                "    dist_penalty = F.relu(S_T - target_level)\n",
                "    loss_dist = dist_penalty.mean()\n",
                "    loss_reg = 0.001 * (log_weights ** 2).mean()\n",
                "    loss = loss_dist + loss_reg\n",
                "    \n",
                "    loss.backward()\n",
                "    torch.nn.utils.clip_grad_norm_(drift_net.parameters(), 1.0)\n",
                "    optimizer.step()\n",
                "    \n",
                "    if i % 50 == 0:\n",
                "        crash_rate = (S_T < K_crash).float().mean().item()\n",
                "        print(f\"Iter {i:3d}: Loss={loss.item():.4f}, Crash Rate={crash_rate*100:.2f}%\")\n",
                "\n",
                "print(\"Training Complete!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Integrated Gradients êµ¬í˜„ / Implementation\n",
                "\n",
                "**í•µì‹¬ ì•„ì´ë””ì–´ / Core Idea:**\n",
                "$$\\text{Attribution}_i = (x_i - x_i^{\\text{baseline}}) \\times \\int_{\\alpha=0}^{1} \\frac{\\partial F(x^{\\text{baseline}} + \\alpha(x - x^{\\text{baseline}}))}{\\partial x_i} d\\alpha$$\n",
                "\n",
                "- **Baseline**: ê¸°ì¤€ì  (ì˜ˆ: í‰ê·  ì£¼ê°€, í‰ê·  ë³€ë™ì„±)\n",
                "- **Input**: ë¶„ì„í•˜ê³ ì í•˜ëŠ” íŠ¹ì • ì…ë ¥ì \n",
                "- **Attributions**: ê° ì…ë ¥ ë³€ìˆ˜(S, v, t)ê°€ ëª¨ë¸ ì¶œë ¥ì— ì–¼ë§ˆë‚˜ ê¸°ì—¬í–ˆëŠ”ì§€"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# =============================================================================\n",
                "# Integrated Gradients í•¨ìˆ˜ ì •ì˜\n",
                "# Define Integrated Gradients Function\n",
                "# =============================================================================\n",
                "\n",
                "def integrated_gradients(model, baseline_inputs, target_inputs, steps=50):\n",
                "    \"\"\"\n",
                "    Integrated Gradientsë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.\n",
                "    Computes Integrated Gradients for the given inputs.\n",
                "    \n",
                "    Args:\n",
                "        model: DriftNet ëª¨ë¸ / DriftNet model\n",
                "        baseline_inputs: ê¸°ì¤€ì  (S, v, t) íŠœí”Œ / Baseline (S, v, t) tuple\n",
                "        target_inputs: ë¶„ì„ ëŒ€ìƒ (S, v, t) íŠœí”Œ / Target (S, v, t) tuple\n",
                "        steps: ì ë¶„ êµ¬ê°„ ìˆ˜ / Number of integration steps\n",
                "    \n",
                "    Returns:\n",
                "        attributions: ê° ì…ë ¥ì˜ ê¸°ì—¬ë„ ë”•ì…”ë„ˆë¦¬ / Attribution dict for each input\n",
                "    \"\"\"\n",
                "    model.eval()\n",
                "    \n",
                "    # ê¸°ì¤€ì ê³¼ ëŒ€ìƒì  ë¶„ë¦¬ / Unpack baseline and target\n",
                "    S_base, v_base, t_base = baseline_inputs\n",
                "    S_target, v_target, t_target = target_inputs\n",
                "    \n",
                "    # í…ì„œë¡œ ë³€í™˜ / Convert to tensors\n",
                "    S_base = torch.tensor([S_base], device=device, dtype=torch.float32)\n",
                "    v_base = torch.tensor([v_base], device=device, dtype=torch.float32)\n",
                "    t_base = torch.tensor([t_base], device=device, dtype=torch.float32)\n",
                "    \n",
                "    S_target = torch.tensor([S_target], device=device, dtype=torch.float32)\n",
                "    v_target = torch.tensor([v_target], device=device, dtype=torch.float32)\n",
                "    t_target = torch.tensor([t_target], device=device, dtype=torch.float32)\n",
                "    \n",
                "    # ê·¸ë˜ë””ì–¸íŠ¸ ëˆ„ì ìš© / Accumulate gradients\n",
                "    grad_S_sum = torch.zeros_like(S_base)\n",
                "    grad_v_sum = torch.zeros_like(v_base)\n",
                "    grad_t_sum = torch.zeros_like(t_base)\n",
                "    \n",
                "    # ì ë¶„ (Riemann Sum) / Integration via Riemann Sum\n",
                "    for i in range(steps):\n",
                "        alpha = i / steps\n",
                "        \n",
                "        # ë³´ê°„ëœ ì…ë ¥ ìƒì„± / Interpolated inputs\n",
                "        S_interp = S_base + alpha * (S_target - S_base)\n",
                "        v_interp = v_base + alpha * (v_target - v_base)\n",
                "        t_interp = t_base + alpha * (t_target - t_base)\n",
                "        \n",
                "        # ê·¸ë˜ë””ì–¸íŠ¸ í™œì„±í™” / Enable gradients\n",
                "        S_interp.requires_grad_(True)\n",
                "        v_interp.requires_grad_(True)\n",
                "        t_interp.requires_grad_(True)\n",
                "        \n",
                "        # Forward pass\n",
                "        output = model(S_interp, v_interp, t_interp)\n",
                "        \n",
                "        # Backward pass\n",
                "        model.zero_grad()\n",
                "        output.backward()\n",
                "        \n",
                "        # ê·¸ë˜ë””ì–¸íŠ¸ ëˆ„ì  / Accumulate gradients\n",
                "        grad_S_sum += S_interp.grad.detach()\n",
                "        grad_v_sum += v_interp.grad.detach()\n",
                "        grad_t_sum += t_interp.grad.detach()\n",
                "    \n",
                "    # í‰ê·  ê·¸ë˜ë””ì–¸íŠ¸ / Average gradients\n",
                "    avg_grad_S = grad_S_sum / steps\n",
                "    avg_grad_v = grad_v_sum / steps\n",
                "    avg_grad_t = grad_t_sum / steps\n",
                "    \n",
                "    # Attribution = (target - baseline) * avg_gradient\n",
                "    attr_S = (S_target - S_base) * avg_grad_S\n",
                "    attr_v = (v_target - v_base) * avg_grad_v\n",
                "    attr_t = (t_target - t_base) * avg_grad_t\n",
                "    \n",
                "    return {\n",
                "        'S': attr_S.item(),\n",
                "        'v': attr_v.item(),\n",
                "        't': attr_t.item()\n",
                "    }\n",
                "\n",
                "print(\"Integrated Gradients function defined âœ…\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# =============================================================================\n",
                "# XAI ë¶„ì„: ë‹¨ì¼ ê²½ë¡œ í•´ì„\n",
                "# XAI Analysis: Single Path Interpretation\n",
                "# =============================================================================\n",
                "\n",
                "# ê¸°ì¤€ì : ì•ˆì „í•œ ìƒíƒœ (ì´ˆê¸° ê°€ê²©, í‰ê·  ë³€ë™ì„±, ì‹œì‘ ì‹œì )\n",
                "# Baseline: Safe state (initial price, mean volatility, start time)\n",
                "baseline = (S0, v0, 0.0)  # (100, 0.04, 0)\n",
                "\n",
                "# ë¶„ì„ ëŒ€ìƒ: ìœ„í—˜í•œ ìƒíƒœ (í­ë½ ì§ì „ ê°€ê²©, ë†’ì€ ë³€ë™ì„±, ì¤‘ê°„ ì‹œì )\n",
                "# Target: Risky state (near-crash price, high volatility, mid-time)\n",
                "risky_state = (75.0, 0.15, 0.15)  # ì£¼ê°€ 75, ë³€ë™ì„± 15%, ì‹œì  0.15\n",
                "\n",
                "# Integrated Gradients ê³„ì‚° / Compute IG\n",
                "attributions = integrated_gradients(drift_net, baseline, risky_state, steps=100)\n",
                "\n",
                "print(\"=\"*60)\n",
                "print(\"       XAI ANALYSIS: Why is this path risky?\")\n",
                "print(\"=\"*60)\n",
                "print(f\"Baseline (Safe):   S={baseline[0]}, v={baseline[1]:.2f}, t={baseline[2]}\")\n",
                "print(f\"Target (Risky):    S={risky_state[0]}, v={risky_state[1]:.2f}, t={risky_state[2]}\")\n",
                "print(f\"\\nAttributions (ê¸°ì—¬ë„):\")\n",
                "print(f\"  ğŸ“‰ ì£¼ê°€(S) ê¸°ì—¬ë„:      {attributions['S']:.4f}\")\n",
                "print(f\"  ğŸ“Š ë³€ë™ì„±(v) ê¸°ì—¬ë„:    {attributions['v']:.4f}\")\n",
                "print(f\"  â° ì‹œê°„(t) ê¸°ì—¬ë„:      {attributions['t']:.4f}\")\n",
                "\n",
                "# ê¸°ì—¬ë„ ë¹„ìœ¨ ê³„ì‚° / Calculate contribution percentages\n",
                "total = abs(attributions['S']) + abs(attributions['v']) + abs(attributions['t'])\n",
                "if total > 0:\n",
                "    pct_S = abs(attributions['S']) / total * 100\n",
                "    pct_v = abs(attributions['v']) / total * 100\n",
                "    pct_t = abs(attributions['t']) / total * 100\n",
                "    print(f\"\\në¹„ìœ¨ / Percentage:\")\n",
                "    print(f\"  ì£¼ê°€(S): {pct_S:.1f}%\")\n",
                "    print(f\"  ë³€ë™ì„±(v): {pct_v:.1f}%\")\n",
                "    print(f\"  ì‹œê°„(t): {pct_t:.1f}%\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# =============================================================================\n",
                "# XAI ì‹œê°í™”: Attribution Bar Chart\n",
                "# XAI Visualization: Attribution Bar Chart\n",
                "# =============================================================================\n",
                "\n",
                "features = ['Price (S)', 'Volatility (v)', 'Time (t)']\n",
                "values = [attributions['S'], attributions['v'], attributions['t']]\n",
                "colors = ['#e74c3c' if v < 0 else '#2ecc71' for v in values]  # Red=negative, Green=positive\n",
                "\n",
                "plt.figure(figsize=(10, 6))\n",
                "bars = plt.barh(features, values, color=colors, edgecolor='black', linewidth=1.5)\n",
                "plt.axvline(x=0, color='black', linestyle='-', linewidth=1)\n",
                "plt.xlabel('Attribution (Contribution to Crash Prediction)', fontsize=12)\n",
                "plt.title('ğŸ” XAI: What Made This Path Risky?', fontsize=14, fontweight='bold')\n",
                "\n",
                "# ê°’ í‘œì‹œ / Show values on bars\n",
                "for bar, val in zip(bars, values):\n",
                "    x_pos = val + 0.01 if val >= 0 else val - 0.05\n",
                "    plt.text(x_pos, bar.get_y() + bar.get_height()/2, f'{val:.3f}', \n",
                "             va='center', ha='left' if val >= 0 else 'right', fontsize=11)\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.show()\n",
                "\n",
                "print(\"\\nğŸ’¡ í•´ì„ / Interpretation:\")\n",
                "print(\"ìŒìˆ˜(-)ëŠ” 'í­ë½ ë°©í–¥ìœ¼ë¡œ ê¸°ì—¬', ì–‘ìˆ˜(+)ëŠ” 'ìƒìŠ¹ ë°©í–¥ìœ¼ë¡œ ê¸°ì—¬'\")\n",
                "print(\"Negative(-) = Contributes to crash, Positive(+) = Contributes to recovery\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# =============================================================================\n",
                "# XAI íˆíŠ¸ë§µ: ì£¼ê°€-ì‹œê°„ ê³µê°„ì—ì„œì˜ ê¸°ì—¬ë„ ë¶„í¬\n",
                "# XAI Heatmap: Attribution Distribution over S-t Space\n",
                "# =============================================================================\n",
                "\n",
                "# ê·¸ë¦¬ë“œ ìƒì„± / Create grid\n",
                "S_range = np.linspace(60, 110, 50)\n",
                "t_range = np.linspace(0.01, T, 25)\n",
                "\n",
                "# ê¸°ì—¬ë„ í–‰ë ¬ ì´ˆê¸°í™” / Initialize attribution matrix\n",
                "attr_matrix_S = np.zeros((len(t_range), len(S_range)))\n",
                "\n",
                "print(\"Computing Attribution Map (this may take a minute)...\")\n",
                "for i, t_val in enumerate(t_range):\n",
                "    for j, S_val in enumerate(S_range):\n",
                "        target = (S_val, v0, t_val)  # ë³€ë™ì„±ì€ ê³ ì •\n",
                "        attrs = integrated_gradients(drift_net, baseline, target, steps=30)\n",
                "        attr_matrix_S[i, j] = attrs['S']  # ì£¼ê°€ ê¸°ì—¬ë„ë§Œ ì¶”ì¶œ\n",
                "    if i % 5 == 0:\n",
                "        print(f\"  Progress: {i+1}/{len(t_range)}\")\n",
                "\n",
                "print(\"Attribution Map computed! âœ…\")\n",
                "\n",
                "# ì‹œê°í™” / Visualization\n",
                "plt.figure(figsize=(12, 8))\n",
                "contour = plt.contourf(t_range, S_range, attr_matrix_S.T, levels=50, cmap='RdBu_r', alpha=0.9)\n",
                "cbar = plt.colorbar(contour)\n",
                "cbar.set_label('Price Attribution (S)', rotation=270, labelpad=20)\n",
                "\n",
                "plt.axhline(y=K_crash, color='white', linestyle='--', linewidth=2, label='Crash Threshold')\n",
                "plt.axhline(y=S0, color='gray', linestyle=':', linewidth=2, label='Initial Price')\n",
                "\n",
                "plt.xlabel('Time (Years)')\n",
                "plt.ylabel('Stock Price')\n",
                "plt.title('ğŸ—ºï¸ XAI Attribution Map: How Much Does Price Affect Crash Risk?', fontsize=13)\n",
                "plt.legend(loc='upper right')\n",
                "plt.tight_layout()\n",
                "plt.show()\n",
                "\n",
                "print(\"\\nğŸ’¡ í•´ì„ / Interpretation:\")\n",
                "print(\"ë¹¨ê°„ìƒ‰: í•´ë‹¹ ì˜ì—­ì—ì„œ 'ì£¼ê°€ í•˜ë½'ì´ í­ë½ ì˜ˆì¸¡ì— ê°•í•˜ê²Œ ê¸°ì—¬\")\n",
                "print(\"íŒŒë€ìƒ‰: í•´ë‹¹ ì˜ì—­ì—ì„œ 'ì£¼ê°€ ìƒìŠ¹'ì´ íšŒë³µ ì˜ˆì¸¡ì— ê°•í•˜ê²Œ ê¸°ì—¬\")\n",
                "print(\"Red: Price drop strongly contributes to crash prediction\")\n",
                "print(\"Blue: Price rise strongly contributes to recovery prediction\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## ğŸ“ ê²°ë¡  / Conclusion\n",
                "\n",
                "**Integrated Gradients**ë¥¼ í†µí•´ AI Crash Generatorê°€ ì–´ë–¤ ìš”ì¸ì„ ê¸°ë°˜ìœ¼ë¡œ í­ë½ì„ ì˜ˆì¸¡í•˜ëŠ”ì§€ ì„¤ëª…í•  ìˆ˜ ìˆê²Œ ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
                "\n",
                "Through **Integrated Gradients**, we can now explain what factors the AI Crash Generator uses to predict crashes.\n",
                "\n",
                "**ì£¼ìš” ë°œê²¬ / Key Findings:**\n",
                "1. ì£¼ê°€(S)ê°€ Crash Threshold(80)ì— ê°€ê¹Œì›Œì§ˆìˆ˜ë¡ Attributionì´ ê°•í•´ì§‘ë‹ˆë‹¤.\n",
                "2. ë³€ë™ì„±(v)ì´ ë†’ì„ìˆ˜ë¡ ë¶ˆí™•ì‹¤ì„±ì´ ì»¤ì ¸ í­ë½ í™•ë¥ ì´ ì¦ê°€í•©ë‹ˆë‹¤.\n",
                "3. ì‹œê°„(t)ì´ ë§Œê¸°ì— ê°€ê¹Œì›Œì§€ë©´ AIì˜ ê°œì…ì´ ë” ê¸‰ê²©í•´ì§‘ë‹ˆë‹¤."
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.10.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
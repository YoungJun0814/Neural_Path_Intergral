{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# 12. Real Data Asian Option Pricing\n",
                "\n",
                "In this notebook, we apply the **Neural Importance Sampling** methodology to price an **Arithmetic Asian Call Option** on the **S&P 500 ETF (SPY)**.\n",
                "\n",
                "## Workflow\n",
                "1.  **Data**: Download real-time SPY option chain data using `yfinance`.\n",
                "2.  **Calibration**: Fit Heston Model parameters ($\\kappa, \\theta, \\xi, \\rho$) to the market implied volatility surface.\n",
                "3.  **Validation**: Use the calibrated parameters to price an Asian Call Option using Neural IS.\n",
                "    - **Objective**: Confirm Variance Reduction > 3.0x with Low Bias (< 2%).\n",
                "    - **Strategy**: **Robust Calibration**. We constrain $\\xi \\le 1.0$ (Vol-of-Vol) to prevent the model from fitting to microstructure noise. This trades a tiny bit of calibration error for massive simulation stability."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# =============================================================================\n",
                "# [MUST BE FIRST] Fix OpenMP Duplicate Library Error\n",
                "# =============================================================================\n",
                "import os\n",
                "os.environ['KMP_DUPLICATE_LIB_OK'] = 'TRUE'\n",
                "\n",
                "import torch\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "from datetime import datetime\n",
                "import yfinance as yf\n",
                "from scipy.optimize import differential_evolution\n",
                "import sys\n",
                "import importlib\n",
                "\n",
                "sys.path.append(os.path.abspath('..'))\n",
                "\n",
                "# Force Reload to pick up code changes\n",
                "import src.physics_engine\n",
                "import src.neural_engine\n",
                "importlib.reload(src.physics_engine)\n",
                "importlib.reload(src.neural_engine)\n",
                "\n",
                "from src.physics_engine import MarketSimulator\n",
                "from src.neural_engine import NeuralImportanceSampler\n",
                "\n",
                "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
                "print(f\"Using device: {device}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Get Market Data (SPY)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "ticker = \"SPY\"\n",
                "spy = yf.Ticker(ticker)\n",
                "\n",
                "# 1. Spot Price\n",
                "try:\n",
                "    S0 = spy.history(period='1d')['Close'].iloc[-1]\n",
                "    print(f\"Current SPY Price: ${S0:.2f}\")\n",
                "except:\n",
                "    S0 = 580.0\n",
                "    print(f\"Failed to get price, using default: ${S0:.2f}\")\n",
                "\n",
                "# 2. Option Chain (Target ~30-60 days expiry)\n",
                "today = datetime.now()\n",
                "target_date = None\n",
                "\n",
                "for exp in spy.options:\n",
                "    exp_dt = datetime.strptime(exp, \"%Y-%m-%d\")\n",
                "    days = (exp_dt - today).days\n",
                "    if 30 <= days <= 75:\n",
                "        target_date = exp\n",
                "        T = days / 365.0\n",
                "        print(f\"Selected Expiry: {target_date} ({days} days, T={T:.4f})\")\n",
                "        break\n",
                "\n",
                "if target_date is None:\n",
                "    target_date = spy.options[2]\n",
                "    exp_dt = datetime.strptime(target_date, \"%Y-%m-%d\")\n",
                "    days = (exp_dt - today).days\n",
                "    T = days / 365.0\n",
                "    print(f\"Fallback Expiry: {target_date} ({days} days, T={T:.4f})\")\n",
                "\n",
                "# 3. Get Strikes & Prices for Calibration\n",
                "opts = spy.option_chain(target_date)\n",
                "calls = opts.calls\n",
                "\n",
                "# Filter liquid ATM options (0.9 * S0 < K < 1.1 * S0)\n",
                "liquid_calls = calls[\n",
                "    (calls['strike'] > S0 * 0.9) & \n",
                "    (calls['strike'] < S0 * 1.1) & \n",
                "    (calls['volume'] > 10)\n",
                "].copy()\n",
                "\n",
                "calib_strikes = liquid_calls['strike'].values\n",
                "calib_prices = liquid_calls['lastPrice'].values\n",
                "\n",
                "print(f\"Calibration Data: {len(calib_prices)} options selected.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Heston Calibration (Fast GPU)\n",
                "We fit $\\kappa, \\theta, \\xi, \\rho$ to minimize Price RMSE."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "r = 0.045 # Risk-free rate assumption\n",
                "dt_calib = 1/252\n",
                "\n",
                "# Simulator for Calibration\n",
                "sim_calib = MarketSimulator(mu=r, kappa=2.0, theta=0.04, xi=0.3, rho=-0.7, device=device)\n",
                "\n",
                "def calibration_loss(params):\n",
                "    kappa, theta, xi, rho = params\n",
                "    \n",
                "    # Sanity Checks\n",
                "    if kappa < 0 or theta < 0 or xi < 0 or abs(rho) > 0.99:\n",
                "        return 1e9\n",
                "        \n",
                "    # Params Dict\n",
                "    p_dict = {'mu': r, 'kappa': kappa, 'theta': theta, 'xi': xi, 'rho': rho}\n",
                "    \n",
                "    try:\n",
                "        # Simulate\n",
                "        S_paths, _ = sim_calib.simulate(\n",
                "            S0=S0, v0=theta, T=T, dt=dt_calib, num_paths=10000, \n",
                "            model_type='heston', override_params=p_dict\n",
                "        )\n",
                "        \n",
                "        S_final = S_paths[:, -1]\n",
                "        if torch.isnan(S_final).any(): return 1e9\n",
                "        \n",
                "        # Martingale Correction\n",
                "        S_corr = S_final * (S0 / torch.mean(S_final))\n",
                "        \n",
                "        # Calc Prices\n",
                "        strikes_gpu = torch.tensor(calib_strikes, device=device).float()\n",
                "        market_prices_gpu = torch.tensor(calib_prices, device=device).float()\n",
                "        \n",
                "        payoffs = torch.maximum(S_corr.unsqueeze(1) - strikes_gpu, torch.tensor(0.0, device=device))\n",
                "        model_prices = torch.mean(payoffs, dim=0) * np.exp(-r*T)\n",
                "        \n",
                "        rmse = torch.sqrt(torch.mean((model_prices - market_prices_gpu)**2))\n",
                "        return rmse.item()\n",
                "        \n",
                "    except:\n",
                "        return 1e9\n",
                "\n",
                "print(\"Calibrating Heston Params... (This might take 30-60s)\")\n",
                "\n",
                "# Robust Calibration: Constrain xi to 1.0 (physically reasonable max) to prevent overfitting to noise\n",
                "bounds = [(0.1, 10.0), (0.001, 0.2), (0.01, 1.0), (-0.95, 0.0)]\n",
                "\n",
                "res = differential_evolution(calibration_loss, bounds, maxiter=15, popsize=10, workers=1, seed=42)\n",
                "\n",
                "calib_kappa, calib_theta, calib_xi, calib_rho = res.x\n",
                "print(f\"\\nâœ… Calibrated Heston Params:\")\n",
                "print(f\"   kappa = {calib_kappa:.4f}\")\n",
                "print(f\"   theta = {calib_theta:.4f}\")\n",
                "print(f\"   xi    = {calib_xi:.4f} (Constrained <= 1.0)\")\n",
                "print(f\"   rho   = {calib_rho:.4f}\")\n",
                "print(f\"   RMSE  = {res.fun:.4f}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Asian Option Pricing (Neural IS)\n",
                "We now price an **ATM Asian Call Option** ($K \\approx S_0$) using the calibrated real-world parameters."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Setup Simulator with Real Params\n",
                "sim = MarketSimulator(\n",
                "    mu=r, kappa=calib_kappa, theta=calib_theta, xi=calib_xi, rho=calib_rho, device=device\n",
                ")\n",
                "\n",
                "K_asian = S0  # ATM\n",
                "dt = 0.0005   # 2000 steps\n",
                "\n",
                "print(f\"Pricing Asian Call (K={K_asian:.2f}) on SPY...\")\n",
                "print(f\"Time Step dt={dt}\")\n",
                "\n",
                "# 1. Standard Monte Carlo Benchmark\n",
                "print(\"Running Standard MC...\")\n",
                "N_mc = 100000\n",
                "with torch.no_grad():\n",
                "    S, _, _, _, running_int_S = sim.simulate_controlled(\n",
                "        S0, calib_theta, T, dt, N_mc, control_fn=None\n",
                "    )\n",
                "    A_T = running_int_S / T\n",
                "    payoff = torch.maximum(A_T - K_asian, torch.tensor(0.0, device=device))\n",
                "    mc_val = payoff * np.exp(-r*T)\n",
                "    mc_price = torch.mean(mc_val).item()\n",
                "    mc_std = torch.std(mc_val).item()\n",
                "\n",
                "print(f\"Standard MC Price: {mc_price:.4f} (Std: {mc_std:.4f})\")\n",
                "\n",
                "# 2. Train Neural IS\n",
                "sampler = NeuralImportanceSampler(sim, hidden_dim=64)\n",
                "optimizer = torch.optim.Adam(sampler.control_net.parameters(), lr=0.001)\n",
                "\n",
                "print(\"\\nTraining Neural IS...\")\n",
                "losses = []\n",
                "prices = []\n",
                "for i in range(301):\n",
                "    sampler.control_net.train()\n",
                "    optimizer.zero_grad()\n",
                "    \n",
                "    control_fn = sampler.get_control_fn()\n",
                "    \n",
                "    S, _, log_w, _, running_int_S = sim.simulate_controlled(\n",
                "        S0, calib_theta, T, dt, 3000, control_fn=control_fn\n",
                "    )\n",
                "    \n",
                "    A_T = running_int_S / T\n",
                "    payoff = torch.maximum(A_T - K_asian, torch.tensor(0.0, device=device))\n",
                "    weighted_payoff = payoff * torch.exp(log_w)\n",
                "    loss = torch.mean(weighted_payoff**2)\n",
                "    \n",
                "    loss.backward()\n",
                "    torch.nn.utils.clip_grad_norm_(sampler.control_net.parameters(), 1.0)\n",
                "    optimizer.step()\n",
                "\n",
                "    losses.append(loss.item())\n",
                "    est_price = torch.mean(weighted_payoff).item() * np.exp(-r*T)\n",
                "    prices.append(est_price)\n",
                "\n",
                "    if i % 50 == 0:\n",
                "        print(f\"Iter {i}: Loss={loss.item():.4f}, Price={est_price:.4f}\")\n",
                "\n",
                "# 3. Final Evaluation\n",
                "print(\"\\nEvaluating Neural IS...\")\n",
                "with torch.no_grad():\n",
                "    sampler.control_net.eval()\n",
                "    control_fn = sampler.get_control_fn()\n",
                "    S, _, log_w, _, running_int_S = sim.simulate_controlled(\n",
                "        S0, calib_theta, T, dt, N_mc, control_fn=control_fn\n",
                "    )\n",
                "    A_T = running_int_S / T\n",
                "    payoff = torch.maximum(A_T - K_asian, torch.tensor(0.0, device=device))\n",
                "    nis_val = payoff * torch.exp(log_w) * np.exp(-r*T)\n",
                "    \n",
                "    nis_price = torch.mean(nis_val).item()\n",
                "    nis_std = torch.std(nis_val).item()\n",
                "\n",
                "print(\"=\"*30)\n",
                "print(f\"Standard MC: {mc_price:.4f} +/- {1.96*mc_std/np.sqrt(N_mc):.4f} (StdDev: {mc_std:.4f})\")\n",
                "print(f\"Neural IS  : {nis_price:.4f} +/- {1.96*nis_std/np.sqrt(N_mc):.4f} (StdDev: {nis_std:.4f})\")\n",
                "\n",
                "ratio = (mc_std / nis_std)**2 if nis_std > 1e-9 else 0\n",
                "print(f\"\\nVariance Reduction Ratio: {ratio:.2f}x\")\n",
                "print(f\"Bias: {abs(nis_price - mc_price) / mc_price * 100:.2f}%\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Visualizations\n",
                "\n",
                "1.  **Training Progress**: Loss and Price convergence.\n",
                "2.  **Control Surface**: The optimal policy $u(A_t, t)$ learned by the neural network."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "plt.figure(figsize=(12, 5))\n",
                "plt.subplot(1, 2, 1)\n",
                "plt.plot(losses)\n",
                "plt.title(\"Loss Curve (Second Moment)\")\n",
                "plt.xlabel(\"Iterations\")\n",
                "plt.ylabel(\"Loss\")\n",
                "\n",
                "plt.subplot(1, 2, 2)\n",
                "plt.plot(prices, label=\"Neural IS\")\n",
                "plt.axhline(mc_price, color='r', linestyle='--', label=\"MC Benchmark\")\n",
                "plt.title(\"Price Convergence\")\n",
                "plt.legend()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Control Surface Visualization\n",
                "# We fix S=S0, v=theta and inspect Control u vs (Time t, Running Average A)\n",
                "\n",
                "t_vals = np.linspace(0.1, T, 30)\n",
                "a_vals = np.linspace(S0 * 0.8, S0 * 1.2, 30)\n",
                "\n",
                "T_grid, A_grid = np.meshgrid(t_vals, a_vals)\n",
                "U_grid = np.zeros_like(T_grid)\n",
                "\n",
                "sampler.control_net.eval()\n",
                "with torch.no_grad():\n",
                "    for i in range(len(t_vals)):\n",
                "        for j in range(len(a_vals)):\n",
                "            t_in = torch.tensor([t_vals[i]], device=device).float()\n",
                "            a_in = torch.tensor([a_vals[j]], device=device).float()\n",
                "            s_in = torch.tensor([S0], device=device).float()\n",
                "            v_in = torch.tensor([calib_theta], device=device).float()\n",
                "            \n",
                "            # Input to forward: S, v, t, avg_S\n",
                "            u_val = sampler.control_net(s_in, v_in, t_in, a_in).cpu().numpy()\n",
                "            U_grid[j, i] = u_val  # Note: Meshgrid indexing is (y, x)\n",
                "\n",
                "from mpl_toolkits.mplot3d import Axes3D\n",
                "\n",
                "fig = plt.figure(figsize=(10, 7))\n",
                "ax = fig.add_subplot(111, projection='3d')\n",
                "surf = ax.plot_surface(T_grid, A_grid, U_grid, cmap='viridis')\n",
                "ax.set_xlabel('Time (t)')\n",
                "ax.set_ylabel('Running Average (A)')\n",
                "ax.set_zlabel('Optimal Control (u)')\n",
                "ax.set_title('Learned Control Policy for Asian Option')\n",
                "fig.colorbar(surf)\n",
                "plt.show()"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.5"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
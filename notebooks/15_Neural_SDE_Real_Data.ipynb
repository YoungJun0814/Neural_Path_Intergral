{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# ğŸ§  Neural SDE: Learning Market Dynamics from Real Data\n",
                "\n",
                "## ëª©í‘œ / Goal\n",
                "Heston Model(ìˆ˜í•™ ê³µì‹)ì„ ë²„ë¦¬ê³ , **S&P 500 ì‹¤ì œ ë°ì´í„°**ë¡œë¶€í„° SDEì˜ Drift/Diffusion í•¨ìˆ˜ë¥¼ í•™ìŠµí•©ë‹ˆë‹¤.\n",
                "\n",
                "Instead of using the Heston Model (mathematical formula), we **learn the Drift/Diffusion functions** directly from real S&P 500 data.\n",
                "\n",
                "## ì™œ Neural SDEì¸ê°€? / Why Neural SDE?\n",
                "- **GAN**: ê·¸ëŸ´ë“¯í•œ ë°ì´í„°ë¥¼ ìƒì„±í•˜ì§€ë§Œ, í™•ë¥  ë°€ë„(PDF)ë¥¼ ëª¨ë¦„ â†’ Girsanov ë¶ˆê°€\n",
                "- **Neural SDE**: SDE êµ¬ì¡°ë¥¼ ìœ ì§€í•˜ë©´ì„œ í•¨ìˆ˜ë¥¼ í•™ìŠµ â†’ **Girsanov Theorem í˜¸í™˜** â†’ NPI ì ìš© ê°€ëŠ¥"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# =============================================================================\n",
                "# í™˜ê²½ ì„¤ì • / Environment Setup\n",
                "# =============================================================================\n",
                "import os\n",
                "os.environ['KMP_DUPLICATE_LIB_OK'] = 'TRUE'\n",
                "\n",
                "import sys\n",
                "sys.path.append('..')\n",
                "\n",
                "import torch\n",
                "import torch.nn as nn\n",
                "import torch.nn.functional as F\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "import pandas as pd\n",
                "from datetime import datetime\n",
                "\n",
                "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
                "print(f\"Using device: {device}\")\n",
                "\n",
                "# torchsde ì„¤ì¹˜ ì—¬ë¶€ í™•ì¸ / Check if torchsde is installed\n",
                "try:\n",
                "    import torchsde\n",
                "    print(\"torchsde is available âœ…\")\n",
                "except ImportError:\n",
                "    print(\"âš ï¸ torchsde is not installed. Run: pip install torchsde\")\n",
                "    print(\"   We will use a custom implementation instead.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. ë°ì´í„° ì¤€ë¹„ / Data Preparation\n",
                "\n",
                "S&P 500 (SPY ETF) ì¼ë³„ ìˆ˜ìµë¥ ì„ ë¡œë“œí•©ë‹ˆë‹¤.\n",
                "\n",
                "Load S&P 500 (SPY ETF) daily returns."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# =============================================================================\n",
                "# ë°ì´í„° ë¡œë“œ / Load Data\n",
                "# ì´ë¯¸ ì €ì¥ëœ ë°ì´í„°ê°€ ìˆìœ¼ë©´ ë¡œë“œ, ì—†ìœ¼ë©´ yfinanceë¡œ ë‹¤ìš´ë¡œë“œ\n",
                "# Load saved data if exists, otherwise download via yfinance\n",
                "# =============================================================================\n",
                "\n",
                "data_path = '../data/processed/spy_returns.csv'\n",
                "\n",
                "if os.path.exists(data_path):\n",
                "    print(f\"Loading data from {data_path}...\")\n",
                "    df = pd.read_csv(data_path, index_col=0, parse_dates=True)\n",
                "else:\n",
                "    print(\"Downloading SPY data from yfinance...\")\n",
                "    try:\n",
                "        import yfinance as yf\n",
                "        spy = yf.download('SPY', start='2010-01-01', end='2024-12-31')\n",
                "        df = pd.DataFrame()\n",
                "        df['Close'] = spy['Close']\n",
                "        df['Returns'] = df['Close'].pct_change()\n",
                "        df = df.dropna()\n",
                "        \n",
                "        # ì €ì¥ / Save\n",
                "        os.makedirs('../data/processed', exist_ok=True)\n",
                "        df.to_csv(data_path)\n",
                "        print(f\"Data saved to {data_path}\")\n",
                "    except ImportError:\n",
                "        print(\"âš ï¸ yfinance not installed. Using synthetic data.\")\n",
                "        # í•©ì„± ë°ì´í„° ìƒì„± / Generate synthetic data\n",
                "        np.random.seed(42)\n",
                "        n_days = 3500\n",
                "        returns = np.random.normal(0.0003, 0.012, n_days)  # í‰ê·  ìˆ˜ìµë¥  0.03%, ë³€ë™ì„± 1.2%\n",
                "        # ê°€ë” í° í•˜ë½ ì¶”ê°€ (Fat Tail ì‹œë®¬ë ˆì´ì…˜) / Add occasional large drops\n",
                "        crash_days = np.random.choice(n_days, size=50, replace=False)\n",
                "        returns[crash_days] = np.random.normal(-0.03, 0.02, 50)\n",
                "        df = pd.DataFrame({'Returns': returns})\n",
                "\n",
                "print(f\"Data shape: {df.shape}\")\n",
                "print(df.describe())"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# =============================================================================\n",
                "# ìˆ˜ìµë¥  ë¶„í¬ ì‹œê°í™” / Visualize Return Distribution\n",
                "# =============================================================================\n",
                "\n",
                "returns = df['Returns'].values\n",
                "\n",
                "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
                "\n",
                "# íˆìŠ¤í† ê·¸ë¨ / Histogram\n",
                "axes[0].hist(returns, bins=100, color='steelblue', alpha=0.7, density=True)\n",
                "axes[0].set_xlabel('Daily Return')\n",
                "axes[0].set_ylabel('Density')\n",
                "axes[0].set_title('SPY Daily Return Distribution')\n",
                "axes[0].axvline(x=0, color='red', linestyle='--')\n",
                "\n",
                "# ëˆ„ì  ìˆ˜ìµë¥  ê³¡ì„  / Cumulative Return\n",
                "cumulative = (1 + df['Returns']).cumprod()\n",
                "axes[1].plot(cumulative.values, color='green')\n",
                "axes[1].set_xlabel('Days')\n",
                "axes[1].set_ylabel('Cumulative Return')\n",
                "axes[1].set_title('SPY Cumulative Return (2010-2024)')\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.show()\n",
                "\n",
                "# í†µê³„ / Statistics\n",
                "print(f\"\\nğŸ“Š Statistics:\")\n",
                "print(f\"  Mean daily return: {returns.mean()*100:.4f}%\")\n",
                "print(f\"  Std (volatility):  {returns.std()*100:.4f}%\")\n",
                "print(f\"  Annualized vol:    {returns.std()*np.sqrt(252)*100:.2f}%\")\n",
                "print(f\"  Skewness:          {pd.Series(returns).skew():.4f}\")\n",
                "print(f\"  Kurtosis:          {pd.Series(returns).kurtosis():.4f}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Neural SDE ëª¨ë¸ ì •ì˜ / Define Neural SDE Model\n",
                "\n",
                "**SDE êµ¬ì¡° / SDE Structure:**\n",
                "$$dS_t = \\mu_{\\theta}(S_t, t) \\cdot S_t \\cdot dt + \\sigma_{\\phi}(S_t, t) \\cdot S_t \\cdot dW_t$$\n",
                "\n",
                "- $\\mu_{\\theta}$: Neural Network (Drift í•¨ìˆ˜ í•™ìŠµ)\n",
                "- $\\sigma_{\\phi}$: Neural Network (Diffusion í•¨ìˆ˜ í•™ìŠµ, Softplusë¡œ ì–‘ìˆ˜ ë³´ì¥)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# =============================================================================\n",
                "# Neural SDE í´ë˜ìŠ¤ ì •ì˜ (Custom Implementation)\n",
                "# Define Neural SDE Class (Custom Implementation without torchsde)\n",
                "# =============================================================================\n",
                "\n",
                "class NeuralDrift(nn.Module):\n",
                "    \"\"\"\n",
                "    Drift í•¨ìˆ˜ë¥¼ í•™ìŠµí•˜ëŠ” ì‹ ê²½ë§.\n",
                "    Neural network that learns the drift function.\n",
                "    \"\"\"\n",
                "    def __init__(self, hidden_dim=64):\n",
                "        super().__init__()\n",
                "        # ì…ë ¥: (log_S, t) â†’ ì¶œë ¥: mu\n",
                "        # Input: (log_S, t) â†’ Output: mu\n",
                "        self.net = nn.Sequential(\n",
                "            nn.Linear(2, hidden_dim),\n",
                "            nn.SiLU(),\n",
                "            nn.Linear(hidden_dim, hidden_dim),\n",
                "            nn.SiLU(),\n",
                "            nn.Linear(hidden_dim, 1)\n",
                "        )\n",
                "    \n",
                "    def forward(self, log_S, t):\n",
                "        \"\"\"\n",
                "        Args:\n",
                "            log_S: ë¡œê·¸ ì£¼ê°€ (batch,) / Log price\n",
                "            t: ì‹œê°„ (batch,) / Time\n",
                "        Returns:\n",
                "            mu: Drift ê°’ (batch,) / Drift value\n",
                "        \"\"\"\n",
                "        x = torch.stack([log_S, t], dim=-1)\n",
                "        return self.net(x).squeeze(-1)\n",
                "\n",
                "\n",
                "class NeuralDiffusion(nn.Module):\n",
                "    \"\"\"\n",
                "    Diffusion í•¨ìˆ˜ë¥¼ í•™ìŠµí•˜ëŠ” ì‹ ê²½ë§.\n",
                "    Neural network that learns the diffusion function.\n",
                "    \"\"\"\n",
                "    def __init__(self, hidden_dim=64):\n",
                "        super().__init__()\n",
                "        self.net = nn.Sequential(\n",
                "            nn.Linear(2, hidden_dim),\n",
                "            nn.SiLU(),\n",
                "            nn.Linear(hidden_dim, hidden_dim),\n",
                "            nn.SiLU(),\n",
                "            nn.Linear(hidden_dim, 1)\n",
                "        )\n",
                "    \n",
                "    def forward(self, log_S, t):\n",
                "        \"\"\"\n",
                "        Args:\n",
                "            log_S: ë¡œê·¸ ì£¼ê°€ (batch,) / Log price\n",
                "            t: ì‹œê°„ (batch,) / Time\n",
                "        Returns:\n",
                "            sigma: Diffusion ê°’ (batch,), í•­ìƒ ì–‘ìˆ˜ / Diffusion value, always positive\n",
                "        \"\"\"\n",
                "        x = torch.stack([log_S, t], dim=-1)\n",
                "        raw = self.net(x).squeeze(-1)\n",
                "        # Softplusë¡œ ì–‘ìˆ˜ ë³´ì¥ / Ensure positive via Softplus\n",
                "        return F.softplus(raw) + 0.01  # ìµœì†Œê°’ 0.01 / Minimum 0.01\n",
                "\n",
                "\n",
                "class NeuralSDEModel(nn.Module):\n",
                "    \"\"\"\n",
                "    Neural SDE ì „ì²´ ëª¨ë¸.\n",
                "    Complete Neural SDE model.\n",
                "    \"\"\"\n",
                "    def __init__(self, hidden_dim=64, device='cuda'):\n",
                "        super().__init__()\n",
                "        self.drift_net = NeuralDrift(hidden_dim).to(device)\n",
                "        self.diff_net = NeuralDiffusion(hidden_dim).to(device)\n",
                "        self.device = device\n",
                "    \n",
                "    def simulate(self, S0, T, dt, num_paths):\n",
                "        \"\"\"\n",
                "        Neural SDEë¡œ ê²½ë¡œ ì‹œë®¬ë ˆì´ì…˜.\n",
                "        Simulate paths using Neural SDE.\n",
                "        \n",
                "        Args:\n",
                "            S0: ì´ˆê¸° ì£¼ê°€ / Initial price\n",
                "            T: ë§Œê¸° / Maturity\n",
                "            dt: ì‹œê°„ ê°„ê²© / Time step\n",
                "            num_paths: ê²½ë¡œ ìˆ˜ / Number of paths\n",
                "        \n",
                "        Returns:\n",
                "            S: ì£¼ê°€ ê²½ë¡œ (num_paths, n_steps+1) / Price paths\n",
                "        \"\"\"\n",
                "        n_steps = int(T / dt)\n",
                "        \n",
                "        # ì´ˆê¸°í™” / Initialize\n",
                "        log_S = torch.log(torch.full((num_paths,), S0, device=self.device))\n",
                "        \n",
                "        # ê²½ë¡œ ì €ì¥ / Store paths\n",
                "        log_S_paths = [log_S.clone()]\n",
                "        \n",
                "        # Euler-Maruyama ì ë¶„ / Euler-Maruyama integration\n",
                "        for step in range(n_steps):\n",
                "            t = step * dt\n",
                "            t_tensor = torch.full((num_paths,), t, device=self.device)\n",
                "            \n",
                "            # Drift & Diffusion ê³„ì‚° / Compute drift & diffusion\n",
                "            mu = self.drift_net(log_S, t_tensor)\n",
                "            sigma = self.diff_net(log_S, t_tensor)\n",
                "            \n",
                "            # Brownian motion\n",
                "            dW = torch.randn(num_paths, device=self.device) * np.sqrt(dt)\n",
                "            \n",
                "            # SDE ì—…ë°ì´íŠ¸ (ë¡œê·¸ ê³µê°„) / SDE update (log space)\n",
                "            # d(log S) = (mu - 0.5*sigma^2) dt + sigma dW (ItÃ´'s Lemma)\n",
                "            log_S = log_S + (mu - 0.5 * sigma**2) * dt + sigma * dW\n",
                "            log_S_paths.append(log_S.clone())\n",
                "        \n",
                "        # ìŠ¤íƒ ë° ì§€ìˆ˜ ë³€í™˜ / Stack and exponentiate\n",
                "        log_S_paths = torch.stack(log_S_paths, dim=1)\n",
                "        S_paths = torch.exp(log_S_paths)\n",
                "        \n",
                "        return S_paths\n",
                "\n",
                "print(\"Neural SDE Model defined âœ…\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Neural SDE í•™ìŠµ / Training Neural SDE\n",
                "\n",
                "**í•™ìŠµ ë°©ë²• / Training Method:**\n",
                "- **Maximum Likelihood Estimation (MLE)**: ì‹¤ì œ ìˆ˜ìµë¥ ì´ ë‚˜ì˜¬ í™•ë¥ ì„ ìµœëŒ€í™”\n",
                "- **Loss**: ìŒì˜ ë¡œê·¸ ìš°ë„ (Negative Log-Likelihood, NLL)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# =============================================================================\n",
                "# í•™ìŠµ ë°ì´í„° ì¤€ë¹„ / Prepare Training Data\n",
                "# =============================================================================\n",
                "\n",
                "# ìˆ˜ìµë¥ ì„ í…ì„œë¡œ ë³€í™˜ / Convert returns to tensor\n",
                "returns_tensor = torch.tensor(returns, dtype=torch.float32, device=device)\n",
                "\n",
                "# ê°€ìƒì˜ ì¼ê°„ ì‹œê°„ ì¶• (0~1 ì‚¬ì´ë¡œ ì •ê·œí™”) / Normalized daily time axis\n",
                "n_days = len(returns)\n",
                "time_tensor = torch.linspace(0, 1, n_days, device=device)\n",
                "\n",
                "# ë¡œê·¸ ê°€ê²© ë³µì› (ëˆ„ì  í•©) / Reconstruct log prices (cumulative sum)\n",
                "log_prices = torch.zeros(n_days + 1, device=device)\n",
                "log_prices[0] = np.log(100)  # ì´ˆê¸° ë¡œê·¸ ê°€ê²© / Initial log price\n",
                "for i in range(n_days):\n",
                "    log_prices[i+1] = log_prices[i] + returns_tensor[i]\n",
                "\n",
                "print(f\"Training data prepared: {n_days} days of returns\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# =============================================================================\n",
                "# í•™ìŠµ ë£¨í”„ / Training Loop\n",
                "# =============================================================================\n",
                "\n",
                "# ëª¨ë¸ ì´ˆê¸°í™” / Initialize model\n",
                "neural_sde = NeuralSDEModel(hidden_dim=64, device=device)\n",
                "optimizer = torch.optim.Adam(neural_sde.parameters(), lr=1e-3)\n",
                "\n",
                "# í•™ìŠµ ì„¤ì • / Training settings\n",
                "num_epochs = 500\n",
                "batch_size = 512\n",
                "dt = 1.0 / 252  # ì¼ê°„ ì‹œê°„ ê°„ê²© / Daily time step\n",
                "\n",
                "loss_history = []\n",
                "\n",
                "print(\"Training Neural SDE on real market data...\")\n",
                "for epoch in range(num_epochs):\n",
                "    optimizer.zero_grad()\n",
                "    \n",
                "    # ëœë¤ ë°°ì¹˜ ìƒ˜í”Œë§ / Random batch sampling\n",
                "    idx = torch.randint(0, n_days - 1, (batch_size,), device=device)\n",
                "    \n",
                "    # í˜„ì¬ ë¡œê·¸ ê°€ê²©ê³¼ ìˆ˜ìµë¥  / Current log prices and returns\n",
                "    log_S_t = log_prices[idx]\n",
                "    r_observed = returns_tensor[idx]  # ê´€ì¸¡ëœ ìˆ˜ìµë¥  / Observed returns\n",
                "    t_batch = time_tensor[idx]\n",
                "    \n",
                "    # Neural SDE ì˜ˆì¸¡ / Neural SDE prediction\n",
                "    mu = neural_sde.drift_net(log_S_t, t_batch)\n",
                "    sigma = neural_sde.diff_net(log_S_t, t_batch)\n",
                "    \n",
                "    # ì˜ˆì¸¡ ìˆ˜ìµë¥  ë¶„í¬ / Predicted return distribution\n",
                "    # r ~ N(mu*dt, sigma^2*dt) (ê·¼ì‚¬) / r ~ N(mu*dt, sigma^2*dt) (approximation)\n",
                "    predicted_mean = mu * dt\n",
                "    predicted_std = sigma * np.sqrt(dt)\n",
                "    \n",
                "    # NLL Loss (Gaussian) / NLL Loss (Gaussian assumption)\n",
                "    nll = 0.5 * ((r_observed - predicted_mean) / predicted_std) ** 2 + torch.log(predicted_std)\n",
                "    loss = nll.mean()\n",
                "    \n",
                "    loss.backward()\n",
                "    torch.nn.utils.clip_grad_norm_(neural_sde.parameters(), 1.0)\n",
                "    optimizer.step()\n",
                "    \n",
                "    loss_history.append(loss.item())\n",
                "    \n",
                "    if epoch % 100 == 0:\n",
                "        avg_mu = mu.mean().item()\n",
                "        avg_sigma = sigma.mean().item()\n",
                "        print(f\"Epoch {epoch:4d}: Loss={loss.item():.4f}, Î¼={avg_mu:.4f}, Ïƒ={avg_sigma:.4f}\")\n",
                "\n",
                "print(\"Training Complete!\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# =============================================================================\n",
                "# í•™ìŠµ ê³¡ì„  ì‹œê°í™” / Visualize Training Curve\n",
                "# =============================================================================\n",
                "\n",
                "plt.figure(figsize=(10, 4))\n",
                "plt.plot(loss_history, color='blue')\n",
                "plt.xlabel('Epoch')\n",
                "plt.ylabel('NLL Loss')\n",
                "plt.title('Neural SDE Training Loss')\n",
                "plt.grid(True, alpha=0.3)\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Neural SDE ê²€ì¦ / Validate Neural SDE\n",
                "\n",
                "í•™ìŠµëœ Neural SDEë¡œ ê²½ë¡œë¥¼ ìƒì„±í•˜ê³ , ì‹¤ì œ SPY ë°ì´í„°ì™€ ë¹„êµí•©ë‹ˆë‹¤.\n",
                "\n",
                "Generate paths with the trained Neural SDE and compare with real SPY data."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# =============================================================================\n",
                "# ê²½ë¡œ ìƒì„± ë° ë¹„êµ / Generate Paths and Compare\n",
                "# =============================================================================\n",
                "\n",
                "# ì‹œë®¬ë ˆì´ì…˜ ì„¤ì • / Simulation settings\n",
                "S0 = 100.0\n",
                "T = 1.0  # 1ë…„ / 1 year\n",
                "dt = 1.0 / 252\n",
                "num_paths = 10000\n",
                "\n",
                "# Neural SDEë¡œ ê²½ë¡œ ìƒì„± / Generate paths with Neural SDE\n",
                "neural_sde.eval()\n",
                "with torch.no_grad():\n",
                "    S_neural = neural_sde.simulate(S0, T, dt, num_paths)\n",
                "\n",
                "S_neural_np = S_neural.cpu().numpy()\n",
                "\n",
                "# ìˆ˜ìµë¥  ì¶”ì¶œ / Extract returns\n",
                "neural_returns = np.diff(np.log(S_neural_np), axis=1).flatten()\n",
                "\n",
                "# ë¹„êµ ì‹œê°í™” / Comparison visualization\n",
                "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
                "\n",
                "# íˆìŠ¤í† ê·¸ë¨ ë¹„êµ / Histogram comparison\n",
                "axes[0].hist(returns, bins=100, alpha=0.5, label='Real SPY', density=True, color='blue')\n",
                "axes[0].hist(neural_returns, bins=100, alpha=0.5, label='Neural SDE', density=True, color='red')\n",
                "axes[0].set_xlabel('Daily Return')\n",
                "axes[0].set_ylabel('Density')\n",
                "axes[0].set_title('Return Distribution: Real vs Neural SDE')\n",
                "axes[0].legend()\n",
                "\n",
                "# ê²½ë¡œ ìƒ˜í”Œ ì‹œê°í™” / Sample path visualization\n",
                "for i in range(20):\n",
                "    axes[1].plot(S_neural_np[i], alpha=0.3, linewidth=0.5)\n",
                "axes[1].set_xlabel('Days')\n",
                "axes[1].set_ylabel('Price')\n",
                "axes[1].set_title('Neural SDE Sample Paths (1 Year)')\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.show()\n",
                "\n",
                "# í†µê³„ ë¹„êµ / Statistical comparison\n",
                "print(f\"\\nğŸ“Š Statistical Comparison:\")\n",
                "print(f\"  {'Metric':<20} {'Real SPY':>12} {'Neural SDE':>12}\")\n",
                "print(f\"  {'-'*44}\")\n",
                "print(f\"  {'Mean Return':<20} {returns.mean()*100:>11.4f}% {neural_returns.mean()*100:>11.4f}%\")\n",
                "print(f\"  {'Std (Volatility)':<20} {returns.std()*100:>11.4f}% {neural_returns.std()*100:>11.4f}%\")\n",
                "print(f\"  {'Skewness':<20} {pd.Series(returns).skew():>12.4f} {pd.Series(neural_returns).skew():>12.4f}\")\n",
                "print(f\"  {'Kurtosis':<20} {pd.Series(returns).kurtosis():>12.4f} {pd.Series(neural_returns).kurtosis():>12.4f}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Neural SDE + NPI: Crash Generation\n",
                "\n",
                "í•™ìŠµëœ Neural SDEë¥¼ ê¸°ë°˜ìœ¼ë¡œ **DriftNetì„ í™œìš©í•œ í­ë½ ìƒì„±**ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.\n",
                "\n",
                "Use the trained Neural SDE with **DriftNet for crash generation**.\n",
                "\n",
                "âš ï¸ **Note**: ì´ ë¶€ë¶„ì€ ê¸°ì¡´ Heston ê¸°ë°˜ ì‹œë®¬ë ˆì´í„°ì™€ Neural SDEë¥¼ í†µí•©í•˜ëŠ” ê³ ê¸‰ ê¸°ëŠ¥ì…ë‹ˆë‹¤. ì¶”í›„ í™•ì¥ ì˜ˆì •ì…ë‹ˆë‹¤."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# =============================================================================\n",
                "# Neural SDE ê¸°ë°˜ í­ë½ ë¶„ì„ (ê°„ë‹¨ ë²„ì „)\n",
                "# Crash Analysis with Neural SDE (Simple Version)\n",
                "# =============================================================================\n",
                "\n",
                "# 20% í­ë½ ì„ê³„ì  / 20% crash threshold\n",
                "CRASH_THRESHOLD = 0.80\n",
                "K_crash = CRASH_THRESHOLD * S0\n",
                "\n",
                "# Terminal ê°€ê²© ì¶”ì¶œ / Extract terminal prices\n",
                "S_T_neural = S_neural_np[:, -1]\n",
                "\n",
                "# í­ë½ í™•ë¥  ê³„ì‚° / Crash probability\n",
                "crash_mask = S_T_neural < K_crash\n",
                "crash_prob = crash_mask.mean()\n",
                "\n",
                "print(f\"\\nğŸ¦¢ Neural SDE Crash Analysis (1 Year Horizon)\")\n",
                "print(f\"=\"*50)\n",
                "print(f\"Crash Threshold: ${K_crash:.2f} (20% drop from ${S0:.2f})\")\n",
                "print(f\"Crash Probability: {crash_prob*100:.2f}%\")\n",
                "print(f\"Crash Events: {crash_mask.sum()} / {num_paths}\")\n",
                "\n",
                "# Terminal ë¶„í¬ ì‹œê°í™” / Visualize terminal distribution\n",
                "plt.figure(figsize=(10, 5))\n",
                "plt.hist(S_T_neural, bins=100, color='steelblue', alpha=0.7)\n",
                "plt.axvline(x=K_crash, color='red', linestyle='--', linewidth=2, label=f'Crash Threshold ({K_crash})')\n",
                "plt.axvline(x=S0, color='gray', linestyle=':', linewidth=2, label=f'Initial Price ({S0})')\n",
                "plt.xlabel('Terminal Price')\n",
                "plt.ylabel('Frequency')\n",
                "plt.title('Neural SDE: Terminal Price Distribution (1 Year)')\n",
                "plt.legend()\n",
                "plt.show()\n",
                "\n",
                "print(f\"\\nğŸ’¡ Insight:\")\n",
                "print(f\"   Neural SDEê°€ ì‹¤ì œ ì‹œì¥ ë°ì´í„°ë¡œë¶€í„° í•™ìŠµí•œ ë™ì—­í•™ì„ ê¸°ë°˜ìœ¼ë¡œ\")\n",
                "print(f\"   í­ë½ í™•ë¥ ì„ ì¶”ì •í–ˆìŠµë‹ˆë‹¤. ì´ëŠ” Heston Modelì˜ ìˆ˜í•™ì  ê°€ì •ì—\")\n",
                "print(f\"   ì˜ì¡´í•˜ì§€ ì•ŠëŠ” Data-Driven ì ‘ê·¼ë²•ì…ë‹ˆë‹¤.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## ğŸ“ ê²°ë¡  / Conclusion\n",
                "\n",
                "**Neural SDE**ë¥¼ í†µí•´ ì‹¤ì œ S&P 500 ë°ì´í„°ë¡œë¶€í„° ì‹œì¥ ë™ì—­í•™(Drift, Diffusion)ì„ í•™ìŠµí–ˆìŠµë‹ˆë‹¤.\n",
                "\n",
                "We learned market dynamics (Drift, Diffusion) from real S&P 500 data using **Neural SDE**.\n",
                "\n",
                "**ì£¼ìš” ì„±ê³¼ / Key Achievements:**\n",
                "1. Heston Model ì—†ì´ ë°ì´í„° ê¸°ë°˜ SDE í•¨ìˆ˜ í•™ìŠµ\n",
                "2. ì‹¤ì œ ìˆ˜ìµë¥  ë¶„í¬ì™€ ìœ ì‚¬í•œ ì‹œë®¬ë ˆì´ì…˜ ê²°ê³¼\n",
                "3. Fat Tail ë° ë¹„ëŒ€ì¹­ì„±(Skewness)ì„ ë” ì˜ í¬ì°©\n",
                "\n",
                "**ë‹¤ìŒ ë‹¨ê³„ / Next Steps:**\n",
                "- Neural SDE + NPI Control (DriftNet) í†µí•©\n",
                "- Girsanov Weight ê³„ì‚° í™•ì¥\n",
                "- ì‹¤ì œ ìœ„ê¸° ì‹œë‚˜ë¦¬ì˜¤ ìƒì„± ë° ë¹„êµ"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.10.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}